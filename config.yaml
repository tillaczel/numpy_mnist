experiment:
  model_path: 'results/params.npy'
  loss_plot_path: 'results/loss.png'

data:
  dev:
    image_path: './data/train-images-idx3-ubyte'
    label_path: './data/train-labels-idx1-ubyte'
    train_fraction: 0.8
  test:
    image_path: './data/train-images-idx3-ubyte'
    label_path: './data/train-labels-idx1-ubyte'
  augmentations: []

model:
  input_dim: 784
  fc_layer_dims:
    - 512
    - 256
    - 128
    - 10
  activation: 'ReLu'
  dropout_p: 0.001  # Set to False if no dropout
  batchnorm: False  # Set to False if no batchnorm

train:
  epochs: 50
  batch_size: 512
  optimizer:
    name: 'adam'
    lr: 0.001
    beta: 0.9
    beta_1: 0.9
    beta_2: 0.999
  lr_decay:
    use: False
    decay_fraction: 0.5
    decay_frequency: 10

eval:
  batch_size: 64

